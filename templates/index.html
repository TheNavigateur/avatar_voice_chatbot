<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Google ADK Voice Chatbot</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            height: 100vh;
            margin: 0;
        }

        .container {
            background: rgba(255, 255, 255, 0.95);
            padding: 2rem;
            border-radius: 20px;
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.2);
            backdrop-filter: blur(10px);
            text-align: center;
            max-width: 500px;
            width: 90%;
        }

        h1 {
            color: #667eea;
            margin-bottom: 1.5rem;
            font-size: 2rem;
        }

        /* Three.js Avatar Container */
        .avatar-container {
            position: relative;
            width: 300px;
            height: 300px;
            margin: 1.5rem auto;
        }

        #avatar-canvas {
            width: 100%;
            height: 100%;
            border-radius: 20px;
            background: transparent;
        }

        #status {
            margin-bottom: 1rem;
            color: #666;
            font-style: italic;
            min-height: 1.5em;
            font-size: 0.95rem;
        }

        .mic-btn {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            border: none;
            border-radius: 50%;
            width: 80px;
            height: 80px;
            font-size: 32px;
            cursor: pointer;
            transition: all 0.3s ease;
            display: flex;
            align-items: center;
            justify-content: center;
            margin: 0 auto;
            box-shadow: 0 4px 15px rgba(102, 126, 234, 0.4);
        }

        .mic-btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 6px 20px rgba(102, 126, 234, 0.5);
        }

        .mic-btn:active {
            transform: scale(0.95);
        }

        .mic-btn.listening {
            background: linear-gradient(135deg, #ea4335 0%, #d32f2f 100%);
            animation: pulse 1.5s infinite;
        }

        @keyframes pulse {
            0% {
                box-shadow: 0 0 0 0 rgba(234, 67, 53, 0.4);
            }

            70% {
                box-shadow: 0 0 0 20px rgba(234, 67, 53, 0);
            }

            100% {
                box-shadow: 0 0 0 0 rgba(234, 67, 53, 0);
            }
        }

        #transcript {
            margin-top: 2rem;
            padding: 1rem;
            background: rgba(248, 249, 250, 0.8);
            border-radius: 12px;
            text-align: left;
            min-height: 100px;
            max-height: 300px;
            overflow-y: auto;
            backdrop-filter: blur(5px);
        }

        .message {
            margin-bottom: 0.5rem;
            padding: 0.5rem;
            border-radius: 8px;
            transition: background 0.2s ease;
        }

        .message:hover {
            background: rgba(102, 126, 234, 0.1);
        }

        .user {
            color: #667eea;
            font-weight: bold;
        }

        .bot {
            color: #333;
        }
    </style>
</head>

<body>
    <div class="container">
        <h1>Google ADK Voice Bot</h1>

        <!-- Three.js 3D Avatar -->
        <div class="avatar-container">
            <canvas id="avatar-canvas"></canvas>
        </div>

        <div id="status">Click the microphone to speak</div>
        <button id="micBtn" class="mic-btn">ðŸŽ¤</button>
        <div id="transcript"></div>
    </div>

    <!-- Three.js Library -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <!-- GLTFLoader for loading 3D models -->
    <script src="https://cdn.jsdelivr.net/npm/three@0.128.0/examples/js/loaders/GLTFLoader.js"></script>

    <!-- Three.js Avatar Setup -->
    <script>
        // Three.js Scene Setup
        let scene, camera, renderer, avatar, mixer, clock;
        let isSpeaking = false;
        let animationId;
        let headBone, jawBone;

        function initThreeJS() {
            const canvas = document.getElementById('avatar-canvas');
            const container = document.querySelector('.avatar-container');

            // Scene
            scene = new THREE.Scene();

            // Camera - positioned for close-up face view like a video call
            camera = new THREE.PerspectiveCamera(
                40,  // Slightly wider field of view for better framing
                container.clientWidth / container.clientHeight,
                0.1,
                1000
            );
            camera.position.set(0, 0, 0.5);  // Closer but not too close - video call distance
            camera.lookAt(0, 0, 0);  // Look at face level

            // Renderer
            renderer = new THREE.WebGLRenderer({
                canvas: canvas,
                alpha: true,
                antialias: true
            });
            renderer.setSize(container.clientWidth, container.clientHeight);
            renderer.setClearColor(0x000000, 0);
            renderer.outputEncoding = THREE.sRGBEncoding;

            // Lights
            const ambientLight = new THREE.AmbientLight(0xffffff, 0.8);
            scene.add(ambientLight);

            const directionalLight = new THREE.DirectionalLight(0xffffff, 1.0);
            directionalLight.position.set(1, 2, 3);
            scene.add(directionalLight);

            const fillLight = new THREE.DirectionalLight(0xffffff, 0.5);
            fillLight.position.set(-1, 0, -1);
            scene.add(fillLight);

            // Clock for animations
            clock = new THREE.Clock();

            // Load Avatar
            loadAvatar();

            // Animation loop
            animate();
        }

        function loadAvatar() {
            const loader = new THREE.GLTFLoader();

            // Using a verified Ready Player Me avatar URL
            // This is a full-body realistic human model
            const modelUrl = 'https://models.readyplayer.me/64bfa15f0e72c63d7c3934a6.glb';

            console.log('Starting to load 3D model from:', modelUrl);
            statusDiv.textContent = "Loading 3D avatar...";

            loader.load(
                modelUrl,
                function (gltf) {
                    console.log('Model loaded successfully!', gltf);
                    avatar = gltf.scene;

                    // Scale and position the model for close-up face view
                    avatar.scale.set(1, 1, 1);
                    avatar.position.set(0, -1.65, 0);  // Slightly lower to center face in view

                    // Make avatar face camera
                    //avatar.rotation.x = 90;
                    //avatar.rotation.set(0, 0, 0);

                    scene.add(avatar);

                    console.log('Avatar added to scene');
                    statusDiv.textContent = "Click the microphone to speak";

                    // Setup animations if available
                    if (gltf.animations && gltf.animations.length > 0) {
                        mixer = new THREE.AnimationMixer(avatar);
                        console.log('Animation mixer created with', gltf.animations.length, 'animations');
                    }

                    // Try to find head and jaw bones for animation
                    let boneCount = 0;
                    avatar.traverse((child) => {
                        if (child.isBone) {
                            boneCount++;
                            console.log('Found bone:', child.name);
                            if (child.name.toLowerCase().includes('head')) {
                                headBone = child;
                                console.log('Head bone found!');
                            }
                            if (child.name.toLowerCase().includes('jaw')) {
                                jawBone = child;
                                console.log('Jaw bone found!');
                            }
                        }
                    });

                    console.log('Total bones found:', boneCount);
                    console.log('Avatar loaded successfully - this is a realistic human model!');
                },
                function (xhr) {
                    const percentComplete = (xhr.loaded / xhr.total * 100).toFixed(0);
                    console.log(percentComplete + '% loaded');
                    statusDiv.textContent = `Loading avatar: ${percentComplete}%`;
                },
                function (error) {
                    console.error('Error loading avatar:', error);
                    console.error('Error details:', error.message);
                    statusDiv.textContent = "Error loading avatar, using fallback";
                    // Fallback: create a simple placeholder
                    createFallbackAvatar();
                }
            );
        }

        function createFallbackAvatar() {
            // Simple fallback if model fails to load
            avatar = new THREE.Group();

            const headGeometry = new THREE.SphereGeometry(0.3, 32, 32);
            const headMaterial = new THREE.MeshPhongMaterial({ color: 0xffd4b3 });
            const head = new THREE.Mesh(headGeometry, headMaterial);
            head.position.y = 1.6;
            avatar.add(head);

            const bodyGeometry = new THREE.CylinderGeometry(0.3, 0.4, 0.8, 16);
            const bodyMaterial = new THREE.MeshPhongMaterial({ color: 0x667eea });
            const body = new THREE.Mesh(bodyGeometry, bodyMaterial);
            body.position.y = 0.8;
            avatar.add(body);

            scene.add(avatar);
            console.log('Using fallback avatar');
        }

        function animate() {
            animationId = requestAnimationFrame(animate);

            // Update animation mixer if it exists
            if (mixer) {
                const delta = clock.getDelta();
                mixer.update(delta);
            }

            // Make avatar always face the camera (if loaded)
            // Commented out to allow manual rotation control
            // if (avatar) {
            //     avatar.lookAt(camera.position);
            // }

            // Speaking animation
            if (isSpeaking && avatar) {
                const time = Date.now() * 0.01;

                // Animate jaw bone if available
                if (jawBone) {
                    jawBone.rotation.x = Math.sin(time) * 0.15;
                }

                // Animate head bone for subtle movement
                if (headBone) {
                    headBone.position.y += Math.sin(time * 0.5) * 0.002;
                }

                // Fallback: animate entire avatar if no bones found
                if (!jawBone && !headBone) {
                    avatar.position.y = Math.sin(time * 0.5) * 0.05;
                }
            } else if (avatar) {
                // Reset to neutral
                if (jawBone) {
                    jawBone.rotation.x = 0;
                }
                if (!jawBone && !headBone) {
                    avatar.position.y = 0;
                }
            }

            renderer.render(scene, camera);
        }

        // Start speaking animation
        function startSpeaking() {
            isSpeaking = true;
        }

        // Stop speaking animation
        function stopSpeaking() {
            isSpeaking = false;
        }

        // Handle window resize
        window.addEventListener('resize', () => {
            const container = document.querySelector('.avatar-container');
            camera.aspect = container.clientWidth / container.clientHeight;
            camera.updateProjectionMatrix();
            renderer.setSize(container.clientWidth, container.clientHeight);
        });

        // Initialize Three.js when page loads
        window.addEventListener('load', initThreeJS);
    </script>

    <script>
        const micBtn = document.getElementById('micBtn');
        const statusDiv = document.getElementById('status');
        const transcriptDiv = document.getElementById('transcript');

        let sessionId = null;
        let recognition;

        if ('webkitSpeechRecognition' in window) {
            recognition = new webkitSpeechRecognition();
            recognition.continuous = false;
            recognition.interimResults = false;
            recognition.lang = 'en-US';

            recognition.onstart = () => {
                micBtn.classList.add('listening');
                statusDiv.textContent = "Listening...";
            };

            recognition.onend = () => {
                micBtn.classList.remove('listening');
                statusDiv.textContent = "Processing...";
            };

            recognition.onresult = async (event) => {
                const transcript = event.results[0][0].transcript;
                addMessage('You', transcript);

                try {
                    const requestBody = { message: transcript };
                    if (sessionId) {
                        requestBody.session_id = sessionId;
                    }

                    const response = await fetch('/chat', {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json'
                        },
                        body: JSON.stringify(requestBody)
                    });


                    const data = await response.json();
                    console.log('Received data:', data);
                    console.log('Response text:', data.response);

                    if (data.session_id) {
                        sessionId = data.session_id;
                    }

                    const botResponse = data.response;
                    console.log('Bot response:', botResponse);
                    addMessage('Bot', botResponse);
                    speak(botResponse);
                    statusDiv.textContent = "Click microphone to speak";

                } catch (error) {
                    console.error('Error:', error);
                    statusDiv.textContent = "Error communicating with server";
                }
            };

            recognition.onerror = (event) => {
                console.error('Speech recognition error', event.error);
                statusDiv.textContent = "Error: " + event.error;
                micBtn.classList.remove('listening');
            };
        } else {
            statusDiv.textContent = "Web Speech API not supported in this browser.";
            micBtn.disabled = true;
        }

        micBtn.addEventListener('click', () => {
            if (micBtn.classList.contains('listening')) {
                recognition.stop();
            } else {
                recognition.start();
            }
        });

        function addMessage(sender, text) {
            const div = document.createElement('div');
            div.className = 'message';
            div.innerHTML = `<span class="${sender.toLowerCase()}">${sender}:</span> ${text}`;
            transcriptDiv.appendChild(div);
            transcriptDiv.scrollTop = transcriptDiv.scrollHeight;
        }

        async function speak(text) {
            try {
                // Call the Google TTS endpoint
                const response = await fetch('/tts', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({
                        text: text,
                        language_code: 'en-GB',
                        voice_name: 'en-GB-Chirp3-HD-Algenib'
                    })
                });

                const data = await response.json();

                // Convert base64 audio to blob and play
                const audioBlob = base64ToBlob(data.audio, 'audio/mp3');
                const audioUrl = URL.createObjectURL(audioBlob);
                const audio = new Audio(audioUrl);

                // Start Three.js avatar animation when audio starts playing
                audio.onplay = () => {
                    startSpeaking();
                };

                // Stop Three.js avatar animation when audio ends
                audio.onended = () => {
                    stopSpeaking();
                    URL.revokeObjectURL(audioUrl);
                };

                audio.play();

            } catch (error) {
                console.error('TTS Error:', error);
                // Fallback to browser speech synthesis
                const utterance = new SpeechSynthesisUtterance(text);

                // Animate Three.js avatar for fallback speech too
                utterance.onstart = () => {
                    startSpeaking();
                };

                utterance.onend = () => {
                    stopSpeaking();
                };

                window.speechSynthesis.speak(utterance);
            }
        }

        function base64ToBlob(base64, mimeType) {
            const byteCharacters = atob(base64);
            const byteNumbers = new Array(byteCharacters.length);
            for (let i = 0; i < byteCharacters.length; i++) {
                byteNumbers[i] = byteCharacters.charCodeAt(i);
            }
            const byteArray = new Uint8Array(byteNumbers);
            return new Blob([byteArray], { type: mimeType });
        }
    </script>
</body>

</html>